{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPnTQBgXtzzYcSNvnaR+Ij",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zcy20051117/machine-learning-code/blob/main/o2o%E4%BB%A3%E7%A0%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvfj0QBa_K3E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')  # ä¸æ˜¾ç¤ºè­¦å‘Š"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P2As_Agir7ZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct4e-hYFg4JU",
        "outputId": "8f50af11-8dcb-4c61-d629-9e4f1ed8f01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare(dataset):\n",
        "\n",
        "    # æºæ•°æ®\n",
        "    data = dataset.copy()\n",
        "    # æŠ˜æ‰£ç‡å¤„ç†\n",
        "    data['is_manjian'] = data['Discount_rate'].map(lambda x: 1 if ':' in str(x) else 0)  # Discount_rateæ˜¯å¦ä¸ºæ»¡å‡\n",
        "    data['discount_rate'] = data['Discount_rate'].map(lambda x: float(x) if ':' not in str(x) else\n",
        "    (float(str(x).split(':')[0]) - float(str(x).split(':')[1])) / float(str(x).split(':')[0]))  # æ»¡å‡å…¨éƒ¨è½¬æ¢ä¸ºæŠ˜æ‰£ç‡\n",
        "    data['min_cost_of_manjian'] = data['Discount_rate'].map(\n",
        "        lambda x: -1 if ':' not in str(x) else int(str(x).split(':')[0]))  # æ»¡å‡çš„æœ€ä½æ¶ˆè´¹\n",
        "    # è·ç¦»å¤„ç†\n",
        "    data['Distance'].fillna(-1, inplace=True)  # ç©ºè·ç¦»å¡«å……ä¸º-1\n",
        "    data['null_distance'] = data['Distance'].map(lambda x: 1 if x == -1 else 0)\n",
        "    # æ—¶é—´å¤„ç†\n",
        "    data['date_received'] = pd.to_datetime(data['Date_received'], format='%Y%m%d')\n",
        "    if 'Date' in data.columns.tolist():  # off_train\n",
        "        data['date'] = pd.to_datetime(data['Date'], format='%Y%m%d')\n",
        "    #print(data['Date_received'])\n",
        "    # è¿”å›\n",
        "    return data"
      ],
      "metadata": {
        "id": "vk5Ty71m_vzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_on(dataset):\n",
        "\n",
        "    # æºæ•°æ®\n",
        "    data = dataset.copy()\n",
        "    # æŠ˜æ‰£ç‡å¤„ç†\n",
        "    data['is_manjian'] = data['Discount_rate'].map(lambda x: 1 if ':' in str(x) else 0)  # Discount_rateæ˜¯å¦ä¸ºæ»¡å‡\n",
        "    data['discount_rate'] = data['Discount_rate'].map(lambda x: float(x) if ':' not in str(x) else\n",
        "    (float(str(x).split(':')[0]) - float(str(x).split(':')[1])) / float(str(x).split(':')[0]))  # æ»¡å‡å…¨éƒ¨è½¬æ¢ä¸ºæŠ˜æ‰£ç‡\n",
        "    data['min_cost_of_manjian'] = data['Discount_rate'].map(\n",
        "        lambda x: -1 if ':' not in str(x) else int(str(x).split(':')[0]))  # æ»¡å‡çš„æœ€ä½æ¶ˆè´¹\n",
        "\n",
        "    # æ—¶é—´å¤„ç†\n",
        "    data['date_received'] = pd.to_datetime(data['Date_received'], format='%Y%m%d')\n",
        "    if 'Date' in data.columns.tolist():  # off_train\n",
        "        data['date'] = pd.to_datetime(data['Date'], format='%Y%m%d')\n",
        "\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "woJ35GqW_v5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label(dataset):\n",
        "\n",
        "    # æºæ•°æ®\n",
        "    data = dataset.copy()\n",
        "    # æ‰“æ ‡:é¢†åˆ¸å15å¤©å†…æ¶ˆè´¹ä¸º1,å¦åˆ™ä¸º0\n",
        "    data['label'] = list(map(lambda x, y: 1 if (x - y).total_seconds() / (60 * 60 * 24) <= 15 else 0, data['date'],\n",
        "                             data['date_received']))\n",
        "    # è¿”å›\n",
        "    return data"
      ],
      "metadata": {
        "id": "lm4BopLu_v8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_simple_feature(label_field):\n",
        "\n",
        "    # æºæ•°æ®\n",
        "    data = label_field.copy()\n",
        "    data['User_id']=data['User_id'].map(int)\n",
        "    data['Merchant_id']=data['Merchant_id'].map(int)\n",
        "    data['Distance']=data['Distance'].map(int)\n",
        "    data['min_cost_of_manjian']=data['min_cost_of_manjian'].map(int)\n",
        "    data['Coupon_id'] = data['Coupon_id'].map(int)  # å°†Coupon_idåˆ—ä¸­floatç±»å‹çš„å…ƒç´ è½¬æ¢ä¸ºintç±»å‹,å› ä¸ºåˆ—ä¸­å­˜åœ¨np.nanå³ç©ºå€¼ä¼šè®©æ•´åˆ—çš„å…ƒç´ å˜ä¸ºfloat\n",
        "    data['Date_received'] = data['Date_received'].map(int)\n",
        "\t# å°†Date_receivedåˆ—ä¸­floatç±»å‹çš„å…ƒç´ è½¬æ¢ä¸ºintç±»å‹,å› ä¸ºåˆ—ä¸­å­˜åœ¨np.nanå³ç©ºå€¼ä¼šè®©æ•´åˆ—çš„å…ƒç´ å˜ä¸ºfloat\n",
        "    data['cnt'] = 1  # æ–¹ä¾¿ç‰¹å¾æå–\n",
        "    # è¿”å›çš„ç‰¹å¾æ•°æ®é›†\n",
        "    feature = data.copy()\n",
        "    print(data.columns.tolist())\n",
        "\n",
        "    #print(data['min_cost_of_manjian'])\n",
        "    # ç”¨æˆ·é¢†åˆ¸æ•°\n",
        "    keys = ['User_id']  # ä¸»é”®\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'  # ç‰¹å¾åå‰ç¼€,ç”±label_fieldå’Œä¸»é”®ç»„æˆ\n",
        "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)  # ä»¥keysä¸ºé”®,'cnt'ä¸ºå€¼,ä½¿ç”¨lenç»Ÿè®¡å‡ºç°çš„æ¬¡æ•°\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt'}).reset_index()  # pivot_tableåkeysä¼šæˆä¸ºindex,ç»Ÿè®¡å‡ºçš„ç‰¹å¾åˆ—ä¼šä»¥valueså³'cnt'å‘½å,å°†å…¶æ”¹åä¸ºç‰¹å¾åå‰ç¼€+ç‰¹å¾æ„ä¹‰,å¹¶å°†indexè¿˜åŸ\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')  # å°†idåˆ—ä¸ç‰¹å¾åˆ—å·¦è¿\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    # ç”¨æˆ·é¢†å–ç‰¹å®šä¼˜æƒ åˆ¸æ•°\n",
        "    keys = ['User_id', 'Coupon_id']  # ä¸»é”®\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'  # ç‰¹å¾åå‰ç¼€,ç”±label_fieldå’Œä¸»é”®ç»„æˆ\n",
        "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)  # ä»¥keysä¸ºé”®,'cnt'ä¸ºå€¼,ä½¿ç”¨lenç»Ÿè®¡å‡ºç°çš„æ¬¡æ•°\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt'}).reset_index()  # pivot_tableåkeysä¼šæˆä¸ºindex,ç»Ÿè®¡å‡ºçš„ç‰¹å¾åˆ—ä¼šä»¥valueså³'cnt'å‘½å,å°†å…¶æ”¹åä¸ºç‰¹å¾åå‰ç¼€+ç‰¹å¾æ„ä¹‰,å¹¶å°†indexè¿˜åŸ\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')  # å°†idåˆ—ä¸ç‰¹å¾åˆ—å·¦è¿\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    # ç”¨æˆ·å½“å¤©é¢†åˆ¸æ•°\n",
        "    keys = ['User_id', 'Date_received']  # ä¸»é”®\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'  # ç‰¹å¾åå‰ç¼€,ç”±label_fieldå’Œä¸»é”®ç»„æˆ\n",
        "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)  # ä»¥keysä¸ºé”®,'cnt'ä¸ºå€¼,ä½¿ç”¨lenç»Ÿè®¡å‡ºç°çš„æ¬¡æ•°\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt'}).reset_index()  # pivot_tableåkeysä¼šæˆä¸ºindex,ç»Ÿè®¡å‡ºçš„ç‰¹å¾åˆ—ä¼šä»¥valueså³'cnt'å‘½å,å°†å…¶æ”¹åä¸ºç‰¹å¾åå‰ç¼€+ç‰¹å¾æ„ä¹‰,å¹¶å°†indexè¿˜åŸ\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')  # å°†idåˆ—ä¸ç‰¹å¾åˆ—å·¦è¿\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    # ç”¨æˆ·å½“å¤©é¢†å–ç‰¹å®šä¼˜æƒ åˆ¸æ•°\n",
        "    keys = ['User_id', 'Coupon_id', 'Date_received']  # ä¸»é”®\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'  # ç‰¹å¾åå‰ç¼€,ç”±label_fieldå’Œä¸»é”®ç»„æˆ\n",
        "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)  # ä»¥keysä¸ºé”®,'cnt'ä¸ºå€¼,ä½¿ç”¨lenç»Ÿè®¡å‡ºç°çš„æ¬¡æ•°\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt'}).reset_index()  # pivot_tableåkeysä¼šæˆä¸ºindex,ç»Ÿè®¡å‡ºçš„ç‰¹å¾åˆ—ä¼šä»¥valueså³'cnt'å‘½å,å°†å…¶æ”¹åä¸ºç‰¹å¾åå‰ç¼€+ç‰¹å¾æ„ä¹‰,å¹¶å°†indexè¿˜åŸ\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')  # å°†idåˆ—ä¸ç‰¹å¾åˆ—å·¦è¿\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    # ç”¨æˆ·æ˜¯å¦åœ¨åŒä¸€å¤©é‡å¤é¢†å–äº†ç‰¹å®šä¼˜æƒ åˆ¸\n",
        "    keys = ['User_id', 'Coupon_id', 'Date_received']  # ä¸»é”®\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'  # ç‰¹å¾åå‰ç¼€,ç”±label_fieldå’Œä¸»é”®ç»„æˆ\n",
        "    pivot = pd.pivot_table(data, index=keys, values='cnt',\n",
        "                           aggfunc=lambda x: 1 if len(x) > 1 else 0)  # ä»¥keysä¸ºé”®,'cnt'ä¸ºå€¼,åˆ¤æ–­é¢†å–æ¬¡æ•°æ˜¯å¦å¤§äº1\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'repeat_receive'}).reset_index()  # pivot_tableåkeysä¼šæˆä¸ºindex,ç»Ÿè®¡å‡ºçš„ç‰¹å¾åˆ—ä¼šä»¥valueså³'cnt'å‘½å,å°†å…¶æ”¹åä¸ºç‰¹å¾åå‰ç¼€+ç‰¹å¾æ„ä¹‰,å¹¶å°†indexè¿˜åŸ\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')  # å°†idåˆ—ä¸ç‰¹å¾åˆ—å·¦è¿\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    #ä¼˜æƒ åˆ¸å½“å¤©è¢«é¢†å–æ•°\n",
        "    keys = ['Coupon_id', 'Date_received']\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
        "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt'}).reset_index()\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    #ä¸èƒ½æè·Ÿlabelæœ‰å…³çš„ç‰¹å¾\n",
        "\n",
        "    #ç”¨æˆ·åœ¨ä¸åŒå•†å®¶æ¶ˆè´¹æ¬¡æ•°\n",
        "    keys = ['User_id', 'Merchant_id']\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
        "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt'}).reset_index()\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·åœ¨ä¸åŒå•†å®¶ä½¿ç”¨ä¸åŒä¼˜æƒ åˆ¸æ¬¡æ•°\n",
        "    keys = ['Coupon_id', 'User_id', 'Merchant_id']\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
        "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt'}).reset_index()\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    #å•†å®¶æŠ•æ”¾ä¼˜æƒ åˆ¸æ•°\n",
        "    keys = ['Coupon_id', 'Merchant_id']\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
        "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt'}).reset_index()\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    #å•†å®¶çš„ç‰¹å®šä¼˜æƒ åˆ¸åœ¨å½“å¤©è¢«é¢†å–æ•°\n",
        "    keys = ['Coupon_id', 'Merchant_id', 'Date_received']\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
        "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt'}).reset_index()\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    #å•†å®¶ä¼˜æƒ åˆ¸å½“å¤©è¢«é¢†æ¬¡æ•°\n",
        "    keys = ['Merchant_id', 'Date_received']\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
        "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt'}).reset_index()\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·æœˆåˆé¢†åˆ¸æ•°\n",
        "    keys = ['User_id', 'Coupon_id']\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
        "    pivot = pd.pivot_table(data[data['Date_received']%100<=10], index=keys, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt_pre'}).reset_index()\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    #å•†å®¶è¢«é¢†åˆ¸æ•°\n",
        "    keys = ['Merchant_id']\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
        "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt'}).reset_index()\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·é¢†å–æ»¡ä¸åŒå‡ä¼˜æƒ åˆ¸æ•°é‡\n",
        "    keys = ['User_id', 'min_cost_of_manjian']\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
        "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt_mincost'}).reset_index()\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·ä¸å•†å®¶zhongweiè·ç¦»(è¿™TMä¸åƒå¯¹çš„ä½†aucä¸Šäº†)\n",
        "    keys = ['User_id', 'Merchant_id', 'Distance']\n",
        "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
        "    pivot = pd.pivot_table(data[data['null_distance']==0], index=keys, values='cnt', aggfunc='median')\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt_mid'}).reset_index()\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    #7401,åº”è¯¥æ˜¯æ¦¨å¹²äº†250426-15:40(æ¦¨å¹²ä¸ªp 250427-23ï¼š20)\n",
        "\n",
        "    #åœ¨å†å²åŒºé—´æäº†å‡ ä¸ªç‰¹å¾ï¼Œæ˜¯7407\n",
        "\n",
        "    #ç”¨æˆ·å»åŒä¸€è·ç¦»çš„å•†æˆ·(250428 7412)\n",
        "    keys = ['Distance','User_id']\n",
        "    pivot = pd.pivot_table(data[data['null_distance']==0], index=keys, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={\n",
        "        'cnt': prefixs + 'receive_cnt'}).reset_index()\n",
        "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
        "    feature.fillna(0,inplace=True)\n",
        "\n",
        "    feature = feature.sort_values(by='Date_received')\n",
        "    feature = pd.concat([feature, feature.groupby('User_id')['Date_received'].rank(method='min')], axis=1)\n",
        "    feature.columns = list(feature.columns[:-1]) + ['ç”¨æˆ·ç»„å†…æ’åº']\n",
        "    feature = pd.concat([feature, feature.groupby('Merchant_id')['Date_received'].rank(method='min')], axis=1)\n",
        "    feature.columns = list(feature.columns[:-1]) + ['å•†æˆ·ç»„å†…æ’åº']\n",
        "    feature = feature[[i for i in feature.columns if i not in ['Date_received']]]\n",
        "\n",
        "\n",
        "    #print(feature.columns.tolist())\n",
        "    #æŸåŒ…å“å¥½ç ï¼šå»é™¤é‡å¤åˆ—ï¼ˆ250428â€”23ï¼š08 7418ï¼‰\n",
        "    #feature = feature.loc[:, ~feature.T.duplicated(keep='first')]\n",
        "    #è®°ç€å»é‡å°±è¡Œï¼Œè¿è¡Œæ˜¯çœŸtmæ…¢å‘€\n",
        "    # åˆ é™¤è¾…åŠ©æç‰¹å¾çš„'cnt'\n",
        "    #feature.drop(['cnt'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "    # è¿”å›\n",
        "    return feature"
      ],
      "metadata": {
        "id": "49RCU2AH_v_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_week_feature(label_field):\n",
        "\n",
        "    # æºæ•°æ®\n",
        "    data = label_field.copy()\n",
        "    data['Coupon_id'] = data['Coupon_id'].map(int)  # å°†Coupon_idåˆ—ä¸­floatç±»å‹çš„å…ƒç´ è½¬æ¢ä¸ºintç±»å‹,å› ä¸ºåˆ—ä¸­å­˜åœ¨np.nanå³ç©ºå€¼ä¼šè®©æ•´åˆ—çš„å…ƒç´ å˜ä¸ºfloat\n",
        "    data['Date_received'] = data['Date_received'].map(\n",
        "        int)  # å°†Date_receivedåˆ—ä¸­floatç±»å‹çš„å…ƒç´ è½¬æ¢ä¸ºintç±»å‹,å› ä¸ºåˆ—ä¸­å­˜åœ¨np.nanå³ç©ºå€¼ä¼šè®©æ•´åˆ—çš„å…ƒç´ å˜ä¸ºfloat\n",
        "    # è¿”å›çš„ç‰¹å¾æ•°æ®é›†\n",
        "    feature = data.copy()\n",
        "    feature['week'] = feature['date_received'].map(lambda x: x.weekday())  # æ˜ŸæœŸå‡ \n",
        "    feature['is_weekend'] = feature['week'].map(lambda x: 1 if x == 5 or x == 6 else 0)  # åˆ¤æ–­é¢†åˆ¸æ—¥æ˜¯å¦ä¸ºä¼‘æ¯æ—¥\n",
        "    feature = pd.concat([feature, pd.get_dummies(feature['week'], prefix='week')], axis=1)  # one-hotç¦»æ•£æ˜ŸæœŸå‡ \n",
        "    feature.index = range(len(feature))  # é‡ç½®index\n",
        "    # è¿”å›\n",
        "    return feature"
      ],
      "metadata": {
        "id": "nBkKaCit_wEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_feature(history_field,label_field):\n",
        "    data=history_field.copy()\n",
        "    data['User_id']=data['User_id'].map(int)\n",
        "    data['Date_received']=data['Date_received'].map(int)\n",
        "    data['Date']=data['Date'].fillna(0).map(int)\n",
        "    data['Distance']=data['Distance'].map(int)\n",
        "    data['jiange']=list(map(lambda x,y: (x - y).total_seconds() / (60 * 60 * 24), data['date'],\n",
        "                             data['date_received']))\n",
        "    data['cnt']=1\n",
        "    keys=['User_id']\n",
        "    prefix='unsimple_'+'_'.join(keys)+'_'\n",
        "    user_feat=label_field[keys].drop_duplicates(keep = 'first')\n",
        "\n",
        "    #ç”¨æˆ·é¢†åˆ¸æ•°\n",
        "    pivot = pd.pivot_table(data,index = keys,values = 'cnt',aggfunc = len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns = {'cnt': prefix+'user_received'}).reset_index()\n",
        "    user_feat = pd.merge(user_feat,pivot,on = keys, how = 'left')\n",
        "    user_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·æ ¸é”€æ•°\n",
        "    pivot = pd.pivot_table(data[data['label']==1],index = keys,values = 'cnt',aggfunc = len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns = {'cnt': prefix+'user_hexiao'}).reset_index()\n",
        "    user_feat = pd.merge(user_feat,pivot,on = keys, how = 'left')\n",
        "    user_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·æ ¸é”€ç‡7406\n",
        "    user_feat['user_hexiao_rate']=user_feat[prefix+'user_hexiao']/user_feat[prefix+'user_received']\n",
        "    user_feat.fillna(0,inplace=True)\n",
        "    user_feat.drop([prefix+'user_hexiao',prefix+'user_received'],axis=1,inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·é¢†åˆ¸æ»¡å‡ä¼˜æƒ åˆ¸æ•°(è¿™ä¸ªæœ‰æ²¡æœ‰æ— æ‰€è°“ï¼Œåˆ†éƒ½æ˜¯7407)\n",
        "    pivot = pd.pivot_table(data[data['is_manjian']==1],index = keys,values = 'cnt',aggfunc = len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns = {'cnt': prefix+'user_manjian'}).reset_index()\n",
        "    user_feat = pd.merge(user_feat,pivot,on = keys, how = 'left')\n",
        "    user_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·æ»¡å‡ä¼˜æƒ åˆ¸æ ¸é”€æ•°\n",
        "    pivot = pd.pivot_table(data[(data['label']==1) & (data['is_manjian']==1)],index = keys,values = 'cnt',aggfunc = len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns = {'cnt': prefix+'user_manjian_hexiao'}).reset_index()\n",
        "    user_feat = pd.merge(user_feat,pivot,on = keys, how = 'left')\n",
        "    user_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·æ»¡å‡ä¼˜æƒ åˆ¸æ ¸é”€ç‡(7407  250426-18:17)\n",
        "    user_feat['manjian_hexiao_rate']=user_feat[prefix+'user_manjian_hexiao']/user_feat[prefix+'user_manjian']\n",
        "    user_feat.drop([prefix+'user_manjian_hexiao'],axis=1,inplace=True)\n",
        "    user_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #user_feat = user_feat.loc[:, ~user_feat.T.duplicated(keep='first')]\n",
        "    #print(user_feat.columns.tolist())\n",
        "    return user_feat"
      ],
      "metadata": {
        "id": "ErfLi5ME_wHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_merchant_feat(history_field,label_field):\n",
        "    data=history_field.copy()\n",
        "    data['User_id']=data['User_id'].map(int)\n",
        "    data['Merchant_id']=data['Merchant_id'].map(int)\n",
        "    data['Coupon_id']=data['Coupon_id'].map(int)\n",
        "    data['Date_received'] = data['Date_received'].map(int)\n",
        "    data['is_hexiao']=list(map(lambda x:1 if pd.notnull(x) else 0,data['date']))\n",
        "    data['cnt']=1\n",
        "\n",
        "    feature=data.copy()\n",
        "\n",
        "    keys=['Merchant_id']\n",
        "    prefix='unsimple_'+'_'.join(keys)+'_'\n",
        "    merchant_feat=label_field[keys].drop_duplicates(keep = 'first')\n",
        "\n",
        "    #å•†å®¶zonggongæŠ•ä¼˜æƒ åˆ¸çš„æ•°é‡\n",
        "    pivot = pd.pivot_table(feature, index=keys, values='Coupon_id', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={'Coupon_id': prefix + 'coupon_count'}).reset_index()\n",
        "    merchant_feat = pd.merge(merchant_feat, pivot, on=keys, how='left')\n",
        "    merchant_feat.fillna(0, inplace=True)\n",
        "\n",
        "    #å•†å®¶ä¼˜æƒ åˆ¸è¢«é¢†å–æ¬¡æ•°\n",
        "    pivot = pd.pivot_table(feature, index=keys, values='is_hexiao', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={'is_hexiao': prefix + 'shagnjiabeilingquancishu'}).reset_index()\n",
        "    merchant_feat = pd.merge(merchant_feat, pivot, on=keys, how='left')\n",
        "    merchant_feat.fillna(0, inplace=True)\n",
        "\n",
        "    #å•†å®¶ä¼˜æƒ åˆ¸è¢«é¢†å–åæ ¸é”€æ¬¡æ•°\n",
        "    pivot = pd.pivot_table(feature[feature['label']==1], index=keys, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefix + 'shagnjiabeilingquanhouhexiaocishu'}).reset_index()\n",
        "    merchant_feat = pd.merge(merchant_feat, pivot, on=keys, how='left')\n",
        "    merchant_feat.fillna(0, inplace=True)\n",
        "\n",
        "    #å•†å®¶ä¼˜æƒ åˆ¸è¢«é¢†å–åæ ¸é”€ç‡\n",
        "    merchant_feat['shangjiayonghuhexiaolv']=merchant_feat[prefix + 'shagnjiabeilingquanhouhexiaocishu']/merchant_feat[prefix + 'shagnjiabeilingquancishu']\n",
        "    merchant_feat.fillna(0,inplace=True)\n",
        "\n",
        "    pivot_avg = pd.pivot_table(feature[feature['label'] == 1], index=keys, values='Distance', aggfunc='mean')\n",
        "    pivot_avg = pd.DataFrame(pivot_avg).rename(columns={'Distance': prefix + 'AverageDistanceAfterRedeem'}).reset_index()\n",
        "\n",
        "    # è®¡ç®—æœ€å°è·ç¦»\n",
        "    pivot_min = pd.pivot_table(feature[feature['label'] == 1], index=keys, values='Distance', aggfunc='min')\n",
        "    pivot_min = pd.DataFrame(pivot_min).rename(columns={'Distance': prefix + 'MinDistanceAfterRedeem'}).reset_index()\n",
        "\n",
        "    # è®¡ç®—æœ€å¤§è·ç¦»\n",
        "    pivot_max = pd.pivot_table(feature[feature['label'] == 1], index=keys, values='Distance', aggfunc='max')\n",
        "    pivot_max = pd.DataFrame(pivot_max).rename(columns={'Distance': prefix + 'MaxDistanceAfterRedeem'}).reset_index()\n",
        "\n",
        "    # åˆå¹¶å¹³å‡è·ç¦»æ•°æ®\n",
        "    merchant_feat = pd.merge(merchant_feat, pivot_avg, on=keys, how='left')\n",
        "    # åˆå¹¶æœ€å°è·ç¦»æ•°æ®\n",
        "    merchant_feat = pd.merge(merchant_feat, pivot_min, on=keys, how='left')\n",
        "    # åˆå¹¶æœ€å¤§è·ç¦»æ•°æ®\n",
        "    merchant_feat = pd.merge(merchant_feat, pivot_max, on=keys, how='left')\n",
        "\n",
        "    # å¡«å……ç¼ºå¤±å€¼ä¸º 0\n",
        "    merchant_feat.fillna(0, inplace=True)\n",
        "    data[data['date_received'].notnull()]\n",
        "    #å•†å®¶å¹³å‡æ¯ç§ä¼˜æƒ åˆ¸æ ¸é”€å¤šå°‘å¼ \n",
        "    pivot = pd.pivot_table(data,index = keys,values = 'Coupon_id',aggfunc = lambda x:len(set(x)))\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={'Coupon_id': prefix + 'averange_coupon'}).reset_index()\n",
        "    merchant_feat = pd.merge(merchant_feat, pivot, on=keys, how='left')\n",
        "\n",
        "    # ç­›é€‰å‡ºå·²æ ¸é”€çš„ä¼˜æƒ åˆ¸\n",
        "    redeemed_coupons = feature[feature['label'] == 1]\n",
        "    # æŒ‰å•†å®¶å’Œä¼˜æƒ åˆ¸åˆ†ç»„å¹¶ç»Ÿè®¡æ ¸é”€æ•°é‡\n",
        "    coupon_counts = redeemed_coupons.groupby(['Merchant_id', 'Coupon_id']).size().reset_index(name='RedemptionCount')\n",
        "    # æŒ‰å•†å®¶åˆ†ç»„è®¡ç®—å¹³å‡æ ¸é”€æ•°é‡\n",
        "    average_redemption = coupon_counts.groupby('Merchant_id')['RedemptionCount'].mean().reset_index(name='AverageRedemptionPerCoupon')\n",
        "    # ç¡®ä¿åˆå¹¶é”®çš„æ•°æ®ç±»å‹ä¸€è‡´\n",
        "    merchant_feat['Merchant_id'] = merchant_feat['Merchant_id'].astype(average_redemption['Merchant_id'].dtype)\n",
        "    # è¿›è¡Œåˆå¹¶æ“ä½œ\n",
        "    merchant_feat = pd.merge(merchant_feat, average_redemption, on='Merchant_id', how='left')\n",
        "    # å¡«å……ç¼ºå¤±å€¼ä¸º 0\n",
        "    merchant_feat.fillna(0, inplace=True)\n",
        "    return merchant_feat"
      ],
      "metadata": {
        "id": "v9jI5Iem_wJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_coupon_feature(history_field,label_field):\n",
        "    data=history_field.copy()\n",
        "    data['User_id']=data['User_id'].map(int)\n",
        "    data['Merchant_id']=data['Merchant_id'].map(int)\n",
        "    data['Coupon_id']=data['Coupon_id'].map(int)\n",
        "    data['cnt']=1\n",
        "    data['uhqbeilingqu']=list(map(lambda x:1 if pd.notnull(x) else 0,data['Coupon_id']))\n",
        "    data['is_hexiao']=list(map(lambda x:1 if pd.notnull(x) else 0,data['date']))\n",
        "    data['weilingquan']=list(map(lambda x:1 if pd.notnull(x) else 0,data['Coupon_id']))\n",
        "    data['manjianyhq']=list(data['Discount_rate'].map(lambda x:1 if ':' in str(x) else 0))\n",
        "    data['cnt']=1\n",
        "    #data['Date_received'] = data['Date_received'].fillna(0)\n",
        "   #data['yue']=data['date_received'].apply(yue())\n",
        "    feature=data.copy()\n",
        "\n",
        "    keys=['Coupon_id']\n",
        "    prefix='unsimple_'+'_'.join(keys)+'_'\n",
        "    coupon_feat=label_field[keys].drop_duplicates(keep = 'first')\n",
        "    useless_feat=label_field[keys].drop_duplicates(keep = 'first')\n",
        "\n",
        "\n",
        "    #ä¼˜æƒ åˆ¸è¢«é¢†å–æ•°é‡\n",
        "    pivot = pd.pivot_table(feature[feature.date_received.notnull()],index = keys,values = 'uhqbeilingqu',aggfunc = len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns = {'uhqbeilingqu': prefix+'coupon_lingqu'}).reset_index()\n",
        "    useless_feat = pd.merge(useless_feat,pivot,on = keys, how = 'left')\n",
        "    useless_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #ä¼˜æƒ åˆ¸è¢«æ ¸é”€æ•°é‡\n",
        "    pivot = pd.pivot_table(feature[feature['label']==1],index = keys,values = 'is_hexiao',aggfunc = lambda x:len(x))\n",
        "    pivot = pd.DataFrame(pivot).rename(columns = {'is_hexiao': prefix+'coupon_hexiao'}).reset_index()\n",
        "    useless_feat = pd.merge(useless_feat,pivot,on = keys, how = 'left')\n",
        "    useless_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #ä¼˜æƒ åˆ¸æ ¸é”€ç‡\n",
        "    coupon_feat[prefix+'coupon_hexiaolv']=useless_feat[prefix+'coupon_hexiao']/useless_feat[prefix+'coupon_lingqu']\n",
        "    coupon_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #å¤šå°‘ğŸ’´å¼€å‡\n",
        "    useless_feat['discount_man'] = feature['Discount_rate'].map(lambda x: np.nan if ':' not in x else (str(x).split(':')[0]))\n",
        "    useless_feat['discount_man'] = pd.to_numeric( useless_feat['discount_man'], errors='coerce')\n",
        "    useless_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #å‡å¤šå°‘\n",
        "    useless_feat['discount_jian'] = feature['Discount_rate'].map(lambda x: np.nan if ':' not in x else (str(x).split(':')[1]))\n",
        "    useless_feat['discount_jian'] = pd.to_numeric( useless_feat['discount_jian'], errors='coerce')\n",
        "    useless_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #æŠ˜æ‰£ç‡\n",
        "    coupon_feat['zhekoulv']=( useless_feat['discount_man']- useless_feat['discount_jian'])/ useless_feat['discount_man']\n",
        "    coupon_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #å‘¨å‡ é¢†åˆ¸\n",
        "    coupon_feat['day_of_week'] = feature.date_received.map(lambda x: x.weekday())\n",
        "\n",
        "    #æœˆå‡ é¢†åˆ¸\n",
        "    coupon_feat['day_of_month'] = feature.date_received.map(lambda x: x.month)\n",
        "\n",
        "    #å‘¨å‡ é¢†çš„åˆ¸ä¼—æ•°\n",
        "    pivot = pd.pivot_table(data,index = keys,values = 'date_received',aggfunc = lambda x:x.dt.weekday.mode().values[0])\n",
        "    pivot = pd.DataFrame(pivot).rename(columns = {'date_received': prefix+'zhoujilingyhq'}).reset_index()\n",
        "    coupon_feat = pd.merge(coupon_feat,pivot,on = keys, how = 'left')\n",
        "    coupon_feat.fillna(0,inplace=True)\n",
        "\n",
        "    return coupon_feat"
      ],
      "metadata": {
        "id": "BOheMcKz_wMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_merchant_feature(history_field,label_field):\n",
        "    data=history_field.copy()\n",
        "    data['User_id']=data['User_id'].map(int)\n",
        "    data['Merchant_id']=data['Merchant_id'].map(int)\n",
        "    data['Coupon_id']=data['Coupon_id'].map(int)\n",
        "    data['cnt']=1\n",
        "    data['uhqbeilingqu']=list(map(lambda x:1 if pd.notnull(x) else 0,data['Coupon_id']))\n",
        "    data['is_hexiao']=list(map(lambda x:1 if pd.notnull(x) else 0,data['date']))\n",
        "    data['weilingquan']=list(map(lambda x:1 if pd.notnull(x) else 0,data['Coupon_id']))\n",
        "    data['manjianyhq']=list(data['Discount_rate'].map(lambda x:1 if ':' in str(x) else 0))\n",
        "    feature=data.copy()\n",
        "\n",
        "    keys=['User_id','Merchant_id']\n",
        "    prefix='unsimple_'+'_'.join(keys)+'_'\n",
        "    um_feat=label_field[keys].drop_duplicates(keep = 'first')\n",
        "\n",
        "\n",
        "    #ç”¨æˆ·é¢†å–å•†å®¶çš„ä¼˜æƒ åˆ¸æ¬¡æ•°\n",
        "    pivot = pd.pivot_table(feature, index=keys, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefix + 'yonghu_lignqu_shangjia_yhq_cishu'}).reset_index()\n",
        "    um_feat = pd.merge(um_feat, pivot, on=keys, how='left')\n",
        "    um_feat.fillna(0, inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·é¢†å–å•†å®¶çš„ä¼˜æƒ åˆ¸åæ ¸é”€æ¬¡æ•°\n",
        "    pivot = pd.pivot_table(feature[feature['label']==1], index=keys, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefix + 'yonghu_lignqu_shangjia_yhq_hexiao_cishu'}).reset_index()\n",
        "    um_feat = pd.merge(um_feat, pivot, on=keys, how='left')\n",
        "    um_feat.fillna(0, inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·é¢†å–å•†å®¶çš„ä¼˜æƒ åˆ¸åæ ¸é”€ç‡\n",
        "    um_feat['yong_gai_yhq_hexiaolv']=um_feat[prefix + 'yonghu_lignqu_shangjia_yhq_hexiao_cishu']/um_feat[prefix + 'yonghu_lignqu_shangjia_yhq_cishu']\n",
        "    um_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·é¢†å–å•†å®¶çš„ä¼˜æƒ åˆ¸åä¸æ ¸é”€æ¬¡æ•°\n",
        "    pivot = pd.pivot_table(feature[feature['label']==0], index=keys, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefix + 'yonghu_lignqu_shangjia_yhq_buhexiao_cishu'}).reset_index()\n",
        "    um_feat = pd.merge(um_feat, pivot, on=keys, how='left')\n",
        "    um_feat.fillna(0, inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·é¢†åˆ¸ä¸æ ¸é”€æ•°\n",
        "    key=['User_id']\n",
        "    useless_feat=label_field[keys].drop_duplicates(keep = 'first')\n",
        "    pivot = pd.pivot_table(feature[feature['label']==0], index=key, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefix + 'wdnmd'}).reset_index()\n",
        "    useless_feat = pd.merge(useless_feat, pivot, on=key, how='left')\n",
        "    useless_feat.fillna(0, inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·æ€»æ ¸é”€æ¬¡æ•°\n",
        "    pivot = pd.pivot_table(feature[feature['label']==1], index=key, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefix + 'wdnmdd'}).reset_index()\n",
        "    useless_feat = pd.merge(useless_feat, pivot, on=key, how='left')\n",
        "    useless_feat.fillna(0, inplace=True)\n",
        "\n",
        "    #print(useless_feat.columns.tolist())\n",
        "    #ç”¨æˆ·å¯¹æ¯ä¸ªå•†å®¶çš„ä¸æ ¸é”€æ¬¡æ•°å ç”¨æˆ·æ€»çš„ä¸æ ¸é”€æ¬¡æ•°çš„æ¯”é‡\n",
        "    um_feat['nmsl']=um_feat[prefix + 'yonghu_lignqu_shangjia_yhq_buhexiao_cishu']/useless_feat[prefix + 'wdnmd']\n",
        "    um_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·å¯¹æ¯ä¸ªå•†å®¶çš„ä¼˜æƒ åˆ¸æ ¸é”€æ¬¡æ•°å ç”¨æˆ·æ€»çš„æ ¸é”€æ¬¡æ•°çš„æ¯”é‡\n",
        "    um_feat['nmsll']=um_feat[prefix + 'yonghu_lignqu_shangjia_yhq_hexiao_cishu']/useless_feat[prefix + 'wdnmdd']\n",
        "    um_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #å•†å®¶ä¸æ ¸é”€æ¬¡æ•°\n",
        "    keyes=['Merchant_id']\n",
        "    pivot = pd.pivot_table(feature[feature['label']==0], index=keyes, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefix + 'wdnmddd'}).reset_index()\n",
        "    useless_feat = pd.merge(useless_feat, pivot, on=keyes, how='left')\n",
        "    useless_feat.fillna(0, inplace=True)\n",
        "\n",
        "    #å•†å®¶æ ¸é”€æ¬¡æ•°\n",
        "    pivot = pd.pivot_table(feature[feature['label']==1], index=keyes, values='cnt', aggfunc=len)\n",
        "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefix + 'wdnmdddd'}).reset_index()\n",
        "    useless_feat = pd.merge(useless_feat, pivot, on=keyes, how='left')\n",
        "    useless_feat.fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "    #ç”¨æˆ·å¯¹æ¯ä¸ªå•†å®¶çš„ä¸æ ¸é”€æ¬¡æ•°å å•†å®¶æ€»çš„ä¸æ ¸é”€æ¬¡æ•°çš„æ¯”é‡\n",
        "    um_feat['mlgb']=um_feat[prefix + 'yonghu_lignqu_shangjia_yhq_buhexiao_cishu']/useless_feat[prefix + 'wdnmddd']\n",
        "    um_feat.fillna(0,inplace=True)\n",
        "\n",
        "    #ç”¨æˆ·å¯¹æ¯ä¸ªå•†å®¶çš„ä¼˜æƒ åˆ¸æ ¸é”€æ¬¡æ•°å å•†å®¶æ€»çš„æ ¸é”€æ¬¡æ•°çš„æ¯”é‡\n",
        "    um_feat['mlgbb']=um_feat[prefix + 'yonghu_lignqu_shangjia_yhq_hexiao_cishu']/useless_feat[prefix + 'wdnmdddd']\n",
        "    um_feat.fillna(0,inplace=True)\n",
        "\n",
        "    return um_feat"
      ],
      "metadata": {
        "id": "mm7NQSvy_wPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_history_feature(dataset,history_field,label_field):\n",
        "    # ç”¨æˆ·ç‰¹å¾\n",
        "    user_feat=get_user_feature(history_field,label_field)\n",
        "    merchant_feat=get_merchant_feat(history_field,label_field)\n",
        "    #coupon_feat=get_coupon_feature(history_field,label_field)\n",
        "    user_merchant_feat=get_user_merchant_feature(history_field,label_field)\n",
        "\n",
        "\n",
        "    final_feat=pd.merge(dataset,user_feat,on = ['User_id'],how = 'left')\n",
        "    final_feat=pd.merge(final_feat,merchant_feat,on=['Merchant_id'],how='left')\n",
        "    #final_feat=pd.merge(final_feat,coupon_feat,on=['Coupon_id'],how='left')\n",
        "    final_feat=pd.merge(final_feat,user_merchant_feat,on=['User_id','Merchant_id'],how='left')\n",
        "\n",
        "    return final_feat"
      ],
      "metadata": {
        "id": "q755K-pE_wSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(history_field, middle_field, label_field):\n",
        "\n",
        "    # ç‰¹å¾å·¥ç¨‹\n",
        "    week_feat = get_week_feature(label_field)  # æ—¥æœŸç‰¹å¾\n",
        "    simple_feat = get_simple_feature(label_field)  # ç¤ºä¾‹ç®€å•ç‰¹å¾\n",
        "    \"\"\"\n",
        "    # æ„é€ æ•°æ®é›†\n",
        "    share_characters = list(\n",
        "        set(simple_feat.columns.tolist()) & set(week_feat.columns.tolist()))  # å…±æœ‰å±æ€§,åŒ…æ‹¬idå’Œä¸€äº›åŸºç¡€ç‰¹å¾,ä¸ºæ¯ä¸ªç‰¹å¾å—çš„äº¤é›†\n",
        "    dataset = pd.concat([week_feat, simple_feat.drop(share_characters, axis=1)], axis=1)\n",
        "    \"\"\"\n",
        "    # æ„é€ æ•°æ®é›†\n",
        "    share_characters = list(\n",
        "        set(simple_feat.columns.tolist()) & set(week_feat.columns.tolist()))  # å…±æœ‰å±æ€§,åŒ…æ‹¬idå’Œä¸€äº›åŸºç¡€ç‰¹å¾,ä¸ºæ¯ä¸ªç‰¹å¾å—çš„äº¤é›†\n",
        "    dataset = pd.concat([week_feat, simple_feat.drop(share_characters, axis=1)], axis=1)\n",
        "    dataset=get_history_feature(dataset,history_field,label_field)\n",
        "    # åˆ é™¤æ— ç”¨å±æ€§å¹¶å°†labelç½®äºæœ€åä¸€åˆ—\n",
        "    if 'Date' in dataset.columns.tolist():  # è¡¨ç¤ºè®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
        "        dataset.drop(['Merchant_id', 'Discount_rate', 'Date', 'date_received', 'date'], axis=1, inplace=True)\n",
        "        label = dataset['label'].tolist()\n",
        "        dataset.drop(['label'], axis=1, inplace=True)\n",
        "        dataset['label'] = label\n",
        "    else:  # è¡¨ç¤ºæµ‹è¯•é›†\n",
        "        dataset.drop(['Merchant_id', 'Discount_rate', 'date_received'], axis=1, inplace=True)\n",
        "    # ä¿®æ­£æ•°æ®ç±»å‹\n",
        "    dataset['User_id'] = dataset['User_id'].map(int)\n",
        "    dataset['Coupon_id'] = dataset['Coupon_id'].map(int)\n",
        "    dataset['Date_received'] = dataset['Date_received'].map(int)\n",
        "    dataset['Distance'] = dataset['Distance'].map(int)\n",
        "    if 'label' in dataset.columns.tolist():\n",
        "        dataset['label'] = dataset['label'].map(int)\n",
        "    # å»é‡\n",
        "    dataset.drop_duplicates(keep='first', inplace=True)\n",
        "    dataset.index = range(len(dataset))\n",
        "    # è¿”å›\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "242G5Z9v_wU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_xgb(train, test):\n",
        "\n",
        "    # xgbå‚æ•°\n",
        "    params = {'booster': 'gbtree',\n",
        "              'objective': 'binary:logistic',\n",
        "              'eval_metric': 'auc',\n",
        "              'silent': 1,\n",
        "              'eta': 0.01,\n",
        "              'max_depth': 5,\n",
        "              'min_child_weight': 1,\n",
        "              'gamma': 0,\n",
        "              'lambda': 1,\n",
        "              'colsample_bylevel': 0.7,\n",
        "              'colsample_bytree': 0.7,\n",
        "              'subsample': 0.9,\n",
        "              'scale_pos_weight': 1}\n",
        "    # æ•°æ®é›†\n",
        "    dtrain = xgb.DMatrix(train.drop(['User_id', 'Coupon_id', 'Date_received', 'label'], axis=1), label=train['label'])\n",
        "    dtest = xgb.DMatrix(test.drop(['User_id', 'Coupon_id', 'Date_received'], axis=1))\n",
        "    # è®­ç»ƒ\n",
        "    watchlist = [(dtrain, 'train')]\n",
        "    model = xgb.train(params, dtrain, num_boost_round=2500, evals=watchlist,verbose_eval=50)\n",
        "    # é¢„æµ‹\n",
        "    predict = model.predict(dtest)\n",
        "    # å¤„ç†ç»“æœ\n",
        "    predict = pd.DataFrame(predict, columns=['prob'])\n",
        "    result = pd.concat([test[['User_id', 'Coupon_id', 'Date_received']], predict], axis=1)\n",
        "    # ç‰¹å¾é‡è¦æ€§\n",
        "    feat_importance = pd.DataFrame(columns=['feature_name', 'importance'])\n",
        "    feat_importance['feature_name'] = model.get_score().keys()\n",
        "    feat_importance['importance'] = model.get_score().values()\n",
        "    feat_importance.sort_values(['importance'], ascending=False, inplace=True)\n",
        "    # è¿”å›\n",
        "    return result, feat_importance"
      ],
      "metadata": {
        "id": "UxyVF9e__wXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # æºæ•°æ®\n",
        "    #off_train = pd.read_csv(r'/content/drive/aliyun_o2o/ccf_offline_stage1_train.csv')\n",
        "    #on_train=pd.read_csv(r'D:\\o2o\\ccf_online_stage1_train.csv')\n",
        "    #off_test = pd.read_csv(r'/content/drive/aliyun_o2o/ccf_offline_stage1_test.csv')\n",
        "    train_path = \"/content/drive/My Drive/aliyun_o2o/ccf_offline_stage1_train.csv\"\n",
        "    test_path  = \"/content/drive/My Drive/aliyun_o2o/ccf_offline_stage1_test_revised.csv\"\n",
        "\n",
        "    #è¯»å– CSV æ–‡ä»¶\n",
        "    off_train = pd.read_csv(train_path)\n",
        "    off_test = pd.read_csv(test_path)\n",
        "    # é¢„å¤„ç†\n",
        "    off_train = prepare(off_train)\n",
        "    off_test = prepare(off_test)\n",
        "    #on_train=prepare_on(on_train)\n",
        "    # æ‰“æ ‡\n",
        "    off_train = get_label(off_train)\n",
        "\n",
        "    # åˆ’åˆ†åŒºé—´\n",
        "    # è®­ç»ƒé›†å†å²åŒºé—´ã€ä¸­é—´åŒºé—´ã€æ ‡ç­¾åŒºé—´\n",
        "    train_history_field = off_train[\n",
        "        off_train['date_received'].isin(pd.date_range('2016/3/2', periods=60))]  # [20160302,20160501)\n",
        "    train_middle_field = off_train[off_train['date'].isin(pd.date_range('2016/5/1', periods=15))]  # [20160501,20160516)\n",
        "    train_label_field = off_train[\n",
        "        off_train['date_received'].isin(pd.date_range('2016/5/16', periods=31))]  # [20160516,20160616)\n",
        "    # éªŒè¯é›†å†å²åŒºé—´ã€ä¸­é—´åŒºé—´ã€æ ‡ç­¾åŒºé—´\n",
        "    validate_history_field = off_train[\n",
        "        off_train['date_received'].isin(pd.date_range('2016/1/16', periods=60))]  # [20160116,20160316)\n",
        "    validate_middle_field = off_train[\n",
        "        off_train['date'].isin(pd.date_range('2016/3/16', periods=15))]  # [20160316,20160331)\n",
        "    validate_label_field = off_train[\n",
        "        off_train['date_received'].isin(pd.date_range('2016/3/31', periods=31))]  # [20160331,20160501)\n",
        "    # æµ‹è¯•é›†å†å²åŒºé—´ã€ä¸­é—´åŒºé—´ã€æ ‡ç­¾åŒºé—´\n",
        "    test_history_field = off_train[\n",
        "        off_train['date_received'].isin(pd.date_range('2016/4/17', periods=60))]  # [20160417,20160616)\n",
        "    test_middle_field = off_train[off_train['date'].isin(pd.date_range('2016/6/16', periods=15))]  # [20160616,20160701)\n",
        "    test_label_field = off_test.copy()  # [20160701,20160801)\n",
        "\n",
        "    # æ„é€ è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†\n",
        "    print('æ„é€ è®­ç»ƒé›†')\n",
        "    train = get_dataset(train_history_field, train_middle_field, train_label_field)\n",
        "    print('æ„é€ éªŒè¯é›†')\n",
        "    validate = get_dataset(validate_history_field, validate_middle_field, validate_label_field)\n",
        "    print('æ„é€ æµ‹è¯•é›†')\n",
        "    test = get_dataset(test_history_field, test_middle_field, test_label_field)\n",
        "\n",
        "    # çº¿ä¸‹éªŒè¯\n",
        "\n",
        "    # çº¿ä¸Šè®­ç»ƒ\n",
        "    big_train = pd.concat([train, validate], axis=0)\n",
        "    result, feat_importance = model_xgb(big_train, test)\n",
        "    # ä¿å­˜\n",
        "    #result.to_csv('/content/drive/aliyun_o2o/easy.csv', index=False, header=None)\n",
        "    result.to_csv('/content/drive/My Drive/aliyun_o2o/easy.csv', index=False, header=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yC5zLUj_wat",
        "outputId": "c913c09a-d6b4-4115-e11e-d991c73b36ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ„é€ è®­ç»ƒé›†\n",
            "['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Distance', 'Date_received', 'Date', 'is_manjian', 'discount_rate', 'min_cost_of_manjian', 'null_distance', 'date_received', 'date', 'label', 'cnt']\n",
            "æ„é€ éªŒè¯é›†\n",
            "['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Distance', 'Date_received', 'Date', 'is_manjian', 'discount_rate', 'min_cost_of_manjian', 'null_distance', 'date_received', 'date', 'label', 'cnt']\n",
            "æ„é€ æµ‹è¯•é›†\n",
            "['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Distance', 'Date_received', 'is_manjian', 'discount_rate', 'min_cost_of_manjian', 'null_distance', 'date_received', 'cnt']\n",
            "[0]\ttrain-auc:0.84754\n",
            "[50]\ttrain-auc:0.87294\n",
            "[100]\ttrain-auc:0.87626\n",
            "[150]\ttrain-auc:0.87854\n",
            "[200]\ttrain-auc:0.88109\n",
            "[250]\ttrain-auc:0.88306\n",
            "[300]\ttrain-auc:0.88522\n",
            "[350]\ttrain-auc:0.88703\n",
            "[400]\ttrain-auc:0.88858\n",
            "[450]\ttrain-auc:0.88991\n",
            "[500]\ttrain-auc:0.89103\n",
            "[550]\ttrain-auc:0.89216\n",
            "[600]\ttrain-auc:0.89312\n",
            "[650]\ttrain-auc:0.89397\n",
            "[700]\ttrain-auc:0.89474\n",
            "[750]\ttrain-auc:0.89546\n",
            "[800]\ttrain-auc:0.89615\n",
            "[850]\ttrain-auc:0.89676\n",
            "[900]\ttrain-auc:0.89736\n",
            "[950]\ttrain-auc:0.89788\n",
            "[1000]\ttrain-auc:0.89841\n",
            "[1050]\ttrain-auc:0.89892\n",
            "[1100]\ttrain-auc:0.89946\n",
            "[1150]\ttrain-auc:0.89998\n",
            "[1200]\ttrain-auc:0.90040\n",
            "[1250]\ttrain-auc:0.90083\n",
            "[1300]\ttrain-auc:0.90122\n",
            "[1350]\ttrain-auc:0.90162\n",
            "[1400]\ttrain-auc:0.90201\n",
            "[1450]\ttrain-auc:0.90238\n",
            "[1500]\ttrain-auc:0.90272\n",
            "[1550]\ttrain-auc:0.90307\n",
            "[1600]\ttrain-auc:0.90340\n",
            "[1650]\ttrain-auc:0.90370\n",
            "[1700]\ttrain-auc:0.90398\n",
            "[1750]\ttrain-auc:0.90427\n",
            "[1800]\ttrain-auc:0.90456\n",
            "[1850]\ttrain-auc:0.90482\n",
            "[1900]\ttrain-auc:0.90510\n",
            "[1950]\ttrain-auc:0.90535\n",
            "[2000]\ttrain-auc:0.90561\n",
            "[2050]\ttrain-auc:0.90586\n",
            "[2100]\ttrain-auc:0.90614\n",
            "[2150]\ttrain-auc:0.90638\n",
            "[2200]\ttrain-auc:0.90661\n",
            "[2250]\ttrain-auc:0.90684\n",
            "[2300]\ttrain-auc:0.90704\n",
            "[2350]\ttrain-auc:0.90725\n",
            "[2400]\ttrain-auc:0.90745\n",
            "[2450]\ttrain-auc:0.90767\n",
            "[2499]\ttrain-auc:0.90786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xgb.__version__)"
      ],
      "metadata": {
        "id": "pYFNQr3ambiq",
        "outputId": "523a631f-88fc-4498-8e01-86af6234bd8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j2ocXOnb_W5O"
      }
    }
  ]
}